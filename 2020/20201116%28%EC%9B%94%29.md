## 1. 학습 날짜
+ 2020-11-16(월)

## 2. 학습시간
+ 17:00 ~ 19:00 (자가)   
+ 20:00 ~ 23:00 (자가)
+ 총 학습시간 : 5시간

## 3. 학습 범위 및 주제
+ 컴퓨터 구조 cache

## 4. 동료 학습 방법

## 5. 학습 목표
+ cache 강의 수강 및 학습


## 6. 상세 학습 내용
+ 실제 코딩에 소요한 시간 : 0시간    
+ 컴퓨터구조 강의 수강 : 3시간    

#### Cache   
   
캐시는 SRAM으로 만들어진다. SRAM은 휘발성.    
수십년간 사용되온 SRAM을 대체할 비휘발성의 고속의 저전력의 값싼 메모리의 등장을 기대한다.   
DRAM,SRAM이 비휘발성이 되면, 부팅에 필요한 데이터를 메모리에 부팅할때마다 올릴필요가 없어진다. 메모리에 저장되어 있기 때문에.   
그러면 다시 SSD에서 HDD로 갈 수도 있을 것 같다. SSD는 부팅 속도와 큰 데이터를 주고받을 때 속도가 빠른 것인데, 큰 용량의 HDD 사용하면 큰 데이터를 주고 받을 일도 없어지기 때문에 비싼 SSD를 살 이유가 없어진다. 그런 시대가 올 수도 있다.   
   
PROCESSRO 1ns(1ghz이상은 하니까)   
DRAM은 수백에서 50ns까지 느려진다.   
processor와 DRAM간의 속도 차이(GAP)을 줄이는 것이 관건. 150cycle정도의 차이가 있다. 이게 프로세스입장에서 가장 큰 문제이다. 캐시가 이 문제를 해결한다.   
   
- 9.3 Basic terminologies 용어 암기   
   
hit : 찾고자 하는 데이터를 캐시에서 찾았다.   
hit rate : 해당 캐시에서 hit할 확률   
miss penalty : 못찾았을 때의 패널티, 즉 cpu가 노는 것   
  
EMATc: Tc(c번째 캐시에 hit이 났을 때 엑세스하는 타임) + m(Miss rate) * Tm(그 다음 단계에서 엑세스 타임). miss시 다음 단계로 계속 nesting.    
HDD는 10ms까지 느리다. cpu입장에서는 굉장히 느린 시간.   
   
캐시가 작을수록 속도가 빠르다.   
   
- 9.5 Cache organization   
1. Placement : 데이터를 위치하는 것   
2. Algorithm for lookup : 모든 데이터를 읽지 않기 때문에, 찾는 데이터가 있는지 없는지를 찾는 것이 중요하다.   
3. Validity : 찾은 데이터가 유효한지   
   
- 9.6 Direct-mapped cache organization   
갈 수 있는 위치가 정해져있다.   
plcement   
뒤의(하위) 세자리가 일치하는 위치로 갈 수 있다.   
Cache_Index = Memory_Address mod Cache_Size   
Cache_Tag = Memory_Address/Cache_Size   
앞의 두자리는 엔트리의 태그에 저장한다   
   
실제 메모리는 주소에 가면 데이터만 있으나.   
캐시는 태그와 데이터(content)가 있다.   
   
인덱스를 따라가서, 태그가 같으면 해당 엔트리의 content를 준다.   
태그가 다르면, 데이터가 없는 것이고, 메모리의 다음 레이어로 이동한다.   
   
power를 껐다가 다시 켰을 경우? 랜덤값으로 비트가 정해진다. 데이터를 메모리로 안 가져왔다고 가정   
우연히 태그가 맞아서 갔는데, cpu의 계산이 엉뚱해진다. 연산에 오류가 발생!   
이것을 막을라고 valid bit가 생겼다.   
   
valid를 0으로 설정하면, 데이터가 없다는 의미이다.   
   
메모리를 강제로 어떤 값으로 초기화 할 수는 있으나, 메모리 측면에서 하드웨어가 늘어난다.   
그러나 랜덤으로 나몰라라하면, 하드웨어는 적게 들지만, 계산에 오류가 발생한다.   
   
따라서, power를 껐다가 다시 키면, valid는 모두 0으로 만들고, 나머지는 랜덤으로 정해진다.   
우연히 태그가 맞아도, valid가 0이면, 캐시에 없다고 판단이 된다.   
메모리에서 데이터를 업데이트하면 그 순간 valid 를 1로 만든다.   
캐시도 하나의 subsystem으로 봐야 한다.   
   
- 9.7 Repercussion on pipelined processor design   
Miss on I-Cache: Insert bubbles until contents supplied, 데이터가 올 때까지(명령어가 오기전까지) 파이프라인에 버블을 집어놓는다   
Miss on D-Cache: Insert bubbles into WB stall IF, ID/RR, EXEC, miss가 발생하면 버블을 5 stage에 넣는다.   
   
- 9.8 Basic cache read/write algorithms    
Read Hit : 데이터가 캐시에 존재할 때    
Read Miss ; 데이터가 캐시에 없다. 메모리 주소가 system bus로 가서 메모리의 데이터가 system bus로 cpu에 전달된다.(약 150cycle동안) 또한 data가 cache에 써진다. valid가 1로 바뀌고, tag, data 정보가 바뀐다.   
   
Write-Back : 캐시에는 무조건 써야 한다. 그래야 다시 읽을 수 있기 때문에. cpu register에 공간이 모자르면, 최소 못해도 cache에 써야 한다.   
a를 갱신하여 저장할 때 메모리에 저장하였다면, 다시 읽어올 때 cache에 있었던 old a를 가져오기 때문에, 문제가 발생한다.     
cache에만 쓰는 것은 write-back   
cpu는 다른 일하고 있고, cahce는 데이터를 system bus가 한가할 때, 메모리에 데이터를 쓴다.    
구현이 쉽다.    
Dirty bit : 1이면 dirty. 캐시가 나만 가지고 있다는 표현. system bus를 주시하고 있다가 한가하면 데이터를 보낸다.   
Write-Through의 write buffer는 바로 메모리에 쓰려고 하기 때문에 congestion을 많이 발생시킨다. 그러나 dirty bit로 system bus를 엿보고 있기때문에 system utilization이 더좋다. (대신에 빨리 못 쓴다는 게 문제)   
   
Write-Through : cache에도 쓰고(1clock~수십 clock), 메모리에도 쓰면(150cycle) write-through. 동시에 쓰기 때문에 cpu가 놀아야 한다. 데이터는 바로 저장해야 해서 맘편하기는 하지만, 놀아야 한다.   
write buffer를 만들어 cpu는 다른일을 하고, 메모리에 write한다. cpu가 노는 시간을 조금 줄일 수 있다.   
   
Write-back과 Write-Through를 혼용해서 사용한다. Why?   
Write-through는 cpu가 노는 시간이 길어진다.   
write-back은 multi-core일 때 문제가 된다. 데이터가 항상 메모리에 업데이트 된다고 하면, cpu들이 메모리만 주시하면 되는데, write-back해버리면, 한 cpu가 독자적으로 데이터를 가지고 있기 때문에 문제가 있다. 하드웨어 구현이 더 복잡해진다. 그러한 단점이 있다.   
   
------------------------------------------------------------------------   
9.8.2.3 Comparison of the Write Policies   
   
system bus에는 모든 데이터가 돌아다닌다. 지나가는 데이터가 cpu보다 훨씬 많을 수 있다. 그런 상태를 생각해보면 write-back, through policy를 고려해볼 필요가 있다.   
아무리 write buffer를 넣은들 하더라도, cpu가 blocking 될 소지가 있다. cpu가 기다려야 하는 문제.   
write back은 cpu입장에서 나몰라라임. 그럴 문제가 아예 없는 것임   
   
write through는 버퍼를 만들면 되기 때문에 로직이 단순하고 빠르다.bus를 주시해야 하는 로직보다는 단순하다.   
그러나 high traffic을 bus에 만들고, 메모리 엑세스를 어거지로 하다보니 cpu가 blocking될 수 있고, 다른 하드웨어가 간섭받을 수 있다.   
   
write back은 로직이 추가되지만, 메모리 엑세스의 효율이 높아진다.   
   
DRAM은 randon access이지만, burst read mode라고 sequential access하여 속도를 높이는 모드가 있다. sequential에서 random으로 바뀌면, latency가 느려지고, 효율성이 낮아진다.    
spatial locality : a가져오면 근처의 data도 가져오는 방법. 이는 cache의 hit rate도 높이는 장점이 있고, 또 하나의 장점은 DRAM이 sequential access가 되기 때문에 ,burst mode가 가능해진다. random access보다 속도가 빨라진다. 합이 맞아서 시스템의 효율을 올려준다. 이렇게 자연적으로 아이디어가 맞아들어가면 좋은 연구가 되는 것이다. 안되면 부가적으로 구현이 필요한 것이다.   
   
**Multilevel cache processors may use both**   
– L1 Write through : dirty bit을 자연적으로 가질 수 없다.   
– L2/L3 Write back : L2부터는 상대적으로 L1에 비해 시간이 오래 걸리니까, dirty bit를 가지고 남는 시간 동안 메모리에 쓴다. 메모리 엑세스 효율성이 높아진다.   
하부 구조로의 dirty bit을 가지겠다는 것은 그 레벨의 메모리 엑세스 효율을 높이겠다는 것이고, dirty bit을 안 가지게 되면 시간차가 생기면서 비효율이 생기게 된다.   
   
   
- 9.9.1 Improving cache performance   
miss rate을 낮춰야 한다.(강의자료 오타)   
placement algorithm을 만들어서, 웬만하면 hit이 나도록 한다.   
cache size를 늘려서 자연스레 hit rate을 늘려야 한다.    
근데, miss가 난다고 하더라도 miss penalty를 줄이겠다.   
   
L1 L2 L3를 만들었다는 것은 패널티를 최소화하기 위함이다. miss 되었을 때 DRAM을 바로 가지 않게끔.   
   
- 9.10 Exploiting spatial locality to improve cache performance   
근처에 있는 word도 한번에 다 읽어온다.   
캐시는 multiple word를 같이 저장한다.   
cache block은 cache line이라고도 불린다.   
캐시 라인의 길이도 정할 수 있는데, 벤치마크 테스트를 통해서 최적의 라인길이를 결정한다.   
라인의 길이를 늘려서 라인의 개수를 줄이면, hit rate을 낮춘다. 너무 과도하게 라인길이를 늘리면.   
라인의 길이를 줄여서 라인의 개수를 늘이면, 많은 엔트리를 가지고 있기는 하지만, 주변 데이터를 적게 가지고 있기 때문에 hit rate에 도움이 안 된다..   
따라서 이것을 적절하게 조절해야 한다. 결과적으로 종합적인 지식이 필요하다.   
   
16k blocks : 16000개의 다른 데이터라는 의미.   
   
14bit to index block.   
32-14 -2-2(offset)= 나머지 14bit는 tag bit이 된다. (offset을 제외하고)   
spatial locality의 또 하나의 장점 : 한 캐시 블럭 내의 각 word들이 각각 tag bit을 가질 필요가 없기 때문에. 전체적으로 효율적인 효과를 가져온다는 이론이 존재한다.   
   
word offset : 한 캐시 블락 내에서도 몇 번째 word인지를 확인해야 한다. mux를 써야 한다는 것이다.   
bit offset :  char 읽었을 때 4개의 byte중 하나를 뽑기 위함.   
   
여기는 예가 4word이지만 요즘은 8,16 word를 쓰는 cache도 생기고 있다. 점점 데이터의 양이 많아지고, SW자체가 커지고 있기 때문이다.   
    
L1은 레이싱카, L2는 승용차, L3는 SUV, DRAM은 Dump truck(속도는 느리지만, 데이터를 많이 가진다)    
   
- 9.10.1 Performance implications of increased blocksize   
blocksize가 늘어나면 cache의 total size(엔트리개수)가 줄어든다. 처음에는 miss rate이 낮아지나, 어느순간부터는 miss rate가 높아진다.   
연구를 통해, inflection point를 발견한다.   
   
- 9.11 Flexible placement   
directed map은 캐시에 한 블록이 만들어지면, WS1에서 올 수 있고, WS2에서, WS3에서 올 수 있다.   
극단적이 예로 재수없게 cpu가 WS1,2,3만 계속 쓴다고하면, cache가 계속 miss가 난다. 물론 L2로 넘어가면 몇배수로 크니까, hit이 되겠지만.L1은 계속 miss가 난다.(문제의 정의)   
directed-mapped은 최근에 읽었는데 최근 것임에도 불구하고 나가야 한다. temperal locality 가 희생받는다.   
flexible은 최근에 쓴것을 지우면 안되니까, WS1,2,3 캐시 모두 올 수 있게 만든다. 다음번에 읽을 때는 캐시의 다음 블록에 저장한다.    
most flexible : WS 전부 다 캐시에 올 수 있다. 꽉 찼을 경우 가장 오래전에 있었던 데이터를 빼고 새로 가져온다.   
locality가 캐시의 존재 이유이다. spatial 은 direct-mapped으로 해결할 수 있었으나, temperal locality는 direct-mapped으로 해결할 수 없다.   
꽉 찬 경우 timestamp에서 가장 오래 전에 쓰여진 데이터를 뺀다. empty space가 있으면 빈 공간에 데이터를 넣는다. 따라서 temperal locality를 극대화해서 활용할 수 있다.   
그래서 좋긴 하지만, 하드웨어가 무지하게 커진다.   
   
- 9.11.1 Fully associative cache   
메모리가 줄 서있지 않는다. 인덱스가 없다.   
tag를 통해 뒤죽박죽이 가능하다.   
valid bit가 1이고, tag bit가 같다면, data가 있다는 것이다. data는 mux로 뽑는다.   
most flexible할 수 있는 장점이 있다.   
그러나 단점은 tag bit 이 많이 늘었다. 더 큰 문제는 directed-mapped은 hit을 알기 위해 comparator 1개 and-gate 1개가 필요한 것에 반해, 라인마다 다 가지고 있다. tree 형식으로 mux의 개수가 늘어난다.   
   
vtag : valid&tag   
   
Two-way Set Associative : directed를 2등분. 가로4개는 index로 비교하고, 세로 2개는 vtag로 비교한다.    
엔트리 개수가 줄어들기 때문에 hit rate를 고려해야 한다. (fully는 hit rate으로부터 자유롭다. 하드웨어가 많아서 문제지만)   
   
(page 48)four-way Set Associative    
hit rate은 낮아질 수 있지만, fully보다 하드웨어를 줄일 수있다.   
인덱스 하나에는 4개까지 넣을 수 있다. 4개 중에서 찾아내야 한다.   
최근에 하나를 읽었는데, 그 다음거 읽느랴고 방금 읽은 것을 지워버려야 하는 이슈가 경감이 됬다.(temperal locality) 4번까지는 허용해준다. 2way는 2번까지, fully는 8번까지.   
comparator, and-gate의 개수가 줄어든다. tag bit도 조금 줄어든다.   
그러나 fully보다 temperal locality를 완전히 해결하지는 못한다.   
   
4-way는 16000개의 데이터를 4로 나눈것이니 4000개의 엔트리 라인이 있는 것이다.    
   
여기서도 연구를 통해 최적을 조사한다.        

## 7. 학습 내용에 대한 개인적인 총평
+ CPU와 메모리 사이의 캐시의 MAPPING 방법에 대해 학습하였다.
+ Comparison of the Write Policies에 대한 내용이 인상적이였다. CPU에 대해 SYSTEM BUS에 대한 간섭을 일으킬 우려에 대해서도 고민해야 한다는 점.
+ HIT RATE를 높이기 위한 CACHE의 다양한 POLICY
+ 교수님의 학사 졸업만으로는 기업에서 기계의 maintenance를 10년 넘게 해야한다고 겁을 주셔서 고민이 생겼다
+ 다음은 VIRTUAL MEMORY에 대해 학습할 예정이다.

## 8. 다음 학습 계획
+ DB 프로젝트 진행(HTML, CSS, JAVASCRIPT, FLASK) 학습