## 1. 학습 날짜
+ 2020-12-18(금)

## 2. 학습시간
+ 13:00 ~ 19:00 (자가)   
+ 20:00 ~ 24:00 (자가)
+ 총 학습시간 : 10시간

## 3. 학습 범위 및 주제
+ 컴퓨터구조

## 4. 동료 학습 방법


## 5. 학습 목표
+ predicated execution, loop unrolling 학습
+ superpipeline, superscalar 학습
+ mutithreading 학습


## 6. 상세 학습 내용
+ 실제 코딩에 소요한 시간 : 0시간    
+ 컴퓨터구조 강의 수강 : 5시간    

### Predicated Execution and Loop Unrolling
   
Control Hazard가 branch 때문에 생겼는데, 그러면 프로그램에서 브랜치를 안쓰면 되는 것 아닌가?(역발상)   
   
predicated code는 조건부 field가 있다. 조건부 실행과 무조건 실행을 표현할 수 있다.   
-> ARM ISA를 보면 맨 앞 4비트가 COND이다. 조건부실행 명령어를 ISA에 넣었다.   
(ARM : Advanced RISC Machine) : 임베디드 시스템은 대부분 ARM을 사용한다.   
(RISC : Reduced Instruction Set Computer)   
   
Cond를 보고 명령어를 실행할지 판단한다.   
MIPS처럼 Cond상관없이 명령어를 실행하도록 하려면, Cond를 1110(AL)로 하면 된다.   
cond가 안 맞는다면, 그 명령어를 NOP한다.   
NOPs : no opration   
   
MOV와 같은 동작을 MIPS ISA에서는 add $r1 $0 $r2 로 표현할 수 있다.(MIPS에는 MOV명령어가 없다.)   
모든 CPU가 $0가 있을 것이라고 확신해서는 안된다. 없을 수도 있다.   
CMOV가 필요하니까 만든 것임.   
ISA를 처음 만들 때, C프로그래밍 같은 언어를 완벽하게 번역할 수 있는 체계인가를 검사한다.    
   
1. predicated execution : condition에 의거하여 명령어의 실행여부를 결정한다.   
   
브랜치 프리딕션은 예측 실패 시, stage전체를 flush해야 하므로 penalty가 크다.   
그에 반해, predicated execution은 항상 한 클락만 손해를 본다.   
   
can be -> 무조건 좋은 것은 아니다.   
맞추기 쉬운 브랜치들은 branch prediction이 좋다.   
왜냐면 맞출 확률이 높은데 뭐하러 매번 한 클락씩 손해를 보나.   
맞추기 어려운 브랜치는 predicated execution을 하여 못 맞춰서 패널티 생기는 것보다는 한 클락 손해보는 것이 낫다.   
맞추기 어려운 브랜치를 못 맞추었을 때 flush해야 하는 stage가 평균 1클락 이상이라면, 한 클락 손해보는게 효율적이다.   
   
- 장점   
성능과 에너지 효율성이 좋다.   
control dependency가 있으면, 코드 최적하가 어렵다.   
브랜치가 없어졌기 때문에, 코드 최적화가 쉬워진다. 명령어 순서를 뒤바꾸기 편하다.   
   
- 단점   
100% 맞출 수 있는 명령어인데, 한 클락 flush해야한다면 손해다.   
adaptivity : 적용시키는 게 쉬운일이 아니다.   
predicated execution은 static predication.   
(static : 시스템이 안 돌고 있는 타일. 컴파일 타임,   
dynamic : 시스템이 돌고 있을 타임. 하드웨어로 만든다. 하드웨어에 붙어서 상황을 기억함. global/local history -> dynamic(run-time))     
컴파일 때는 맞추기 어려운데, 다이나믹 때 맞추기 쉬울 수 있다.   
컴파일 타임(static)에 브랜치를 예측하는 것이 쉽지 않다. 특정 부분에서는 쉬울 수 있으나, 전체 브랜치에 대해서는 적용하는게 정확하지 않을 수 있다.   
따라서, 컴파일 타임에는 확실한 브랜치들에만 predicate execution을 적용할 수 있다.   
어떤 브랜치가 맞추기 쉬운 것인지, 어려운 것인지도 알 수 없다. 특정 브랜치는 알 수 있으나, 전체 브랜치 모두를 알기는 어렵다.   
알기 어려운 브랜치는 적용하기가 쉽지 않다.   
   
또 다른 단점은 명령어 체계가 지원해 주어야 한다.(MIPS는 지원안함. ARM은 지원함).   
지원하다고 하면, 추가적인 하드웨어가 필요하다.   
   
   
그런데, 연속적으로 조건이 여러개라면 조건의 개수만큼 손해가 생긴다.   
이런 경우는 predicated execution하면 손해가 크다. 그냥 branch prediction 하는게 좋을 수 있다.   
따라서, 컴파일러는 if문 개수를 보고 판단해서, predicated execution을 할지 말지를 결정해야 한다.   
predicated execution이 도움 될 수 있는 상황은 굉장히 제약적이다.   
   
결국, control hazard 해결할 수 있는 방법은 집단 마무리 체제이다. 쓸 수 있는 방법은 다 쓰는 것임.   
   
2. Loop Unrolling   
루프를 푼다. 브랜치를 없애기 위해서!   
1.루프를 푸는 것은 노가다.   
2.루프를 풀면 명령어의 개수가 늘어난다. 명령어의 개수만큼 메모리의 양이 많아진다.   
   
어떻게 푸냐?   
cpu가 동적으로 for문을 푼다. 명령어 순서들을 큐에 정렬한다.   
명령어 큐의 패턴을 보고 cpu가 for문이라는 것을 알게 되고 for문을 푼다.   
cpu가 풀게 됨으로써, (컴퓨터가 동적으로 푼다. 컴파일러가 static하게 푸는 것이 아니라)   
실행시간이 짧아진다. 브랜치도 없애면서, 16개의 명령어만 처리하여 control hazard를 해결할 수 있다.(1타 2피)   
   
그러나 문제는 단지 for문에서만 풀 수 있다.   
while문은 조건이 있으면 풀 수가 없다.   
while문도 for문으로 바꾸어낼 수 있는 조건이라면, 풀 수 있다.   
   
----------------------------------------------------------------------   
### Super Scalar   
   
- super pipeline : 파이프라인을 균일하게 자를수만 있다면,더 잘게 잘라보자.   
(균일하지 않으면, cycle time이 길어진다. clock frequency가 가장 긴 stage에 바운드된다.)    
stage의 길이가 짧아지기 때문에 clock frequency를 높일 수 있다. (delay time이 줄어들기 때문에) -> 성능 높아짐. (장점)   
균일하게 자를 수 있는 한계가 존재한다.   
   
- super scalar : 자르는게 아니라 두개씩 처리하면 되지 않겠느냐, 그렇다고 성능이 완전히 2배가 되지는 않는다.   
수퍼스케일라 자체로써는 그렇게 좋아지지는 않는다.(멀티 쓰레드가 추가되어야 좋아진다.)   
   
- 수퍼파이프라인 단점   
(1) stage 수가 5단계가 10단계로 늘어난다고 하면, forwarding path가 늘어난다.    
(2) load 명령어의 경우 1clock stall이 되는데, 2개로 나누어버리면 2 clock stall하게 된다.   
더 심각한 상황은 ALU가 반으로 잘린 경우, 뒤의 명령어가 앞의 명령어의 결과를 필요로하는데, 아직 앞의 명령어의 결과가 나오지 않아 stall이 발생하게 되버린다. 이런 경우 자를 수가 없다.   
-> 수퍼파이프라인으로 인한 성능향상이 어느수준 이상은 어렵다.   
(3) 이득이 not linear. (uneven balance)   
   
-> 그래서 수퍼파이프라인 대신 수퍼스케일라를 생각하게 되었다.   
   
VLIW는 수퍼스케일라와 비슷한데, 더 옛날것   
VLIW : 한가지 명령어가 여러 데이터 연산을 동시에 수행   
수퍼스케일라 : 여러 명령어가 동시에 수행   
   
수퍼스케일라의 문제 : 문제들이 파이프라인 스테이지별로 있는게 아니라. 같이 들어오는 명령어끼리 발생하게 되었다.   
문제가 해결되는 것이 아니라 오히려 3가지 문제가 더 가중된다.   
그럼 이게 과연 좋은 방법인가?   
-> 멀티 쓰레딩 이후 결과가 나온다.   
   
스퍼스케일라를 좀더 잘쓰기 위한 방법 : OoO(명령어 순서를 뒤바꾸겠다)   
   
명령어를 fetch한다. : 메모리에서 명령어를 가져오는 시점/행위를 의미한다.   
명령어를 issue 한다. : 명령어를 ALU에 집어넣는 시점/행위를 의미한다.   
completion : ALU에서 연산이 끝나는 시점/행위를 의미한다.   
commit : register file에 data를 write back하는 시점/행위를 한다. 저장소에 안전하게 저장하는 시점.   
   
in-order : 순서대로   
out-of-order :  순서를 뒤짚어서   
보통 commit 은 순서대로 하는데, 어떤 cpu는 commit의 순서까지 뒤집기도 한다.   
   
OoO(Out of Order)의 의미?    
순서를 바꾸어서 number of clock cycles을 조금 줄일 수가 있다.   
   
(page11) I2 : needs a execute cycle.(다른말이 없으면 한클락 필요 )   
   
cpu가 명령어들을 분석해서 순서를 바꿔서 성능은 높일 수 있다. 그러나 계산결과는 bad    
   
(page18)   
3가지 dependency : MIPS에서는 일어나지 않지만, 지금 세가지 명령어를 동시에 처리한다고 했을 때, 순서가 바뀌면 결과도 바뀌는 문제가 발생   
   
output dependency(WAW) :순서바뀌면 결과도 바뀐다.   
마찬가지로, anti dependency(WAR) 도 OoO 로 순서가 바뀌면 결과도 바뀐다.   
   
계산 결과가 틀린데, 왜 쓰나?   
해결책이 있어서 사용한다.   
dependency issue에 대한 해결책 -> Register renaming   
뒤짚었을 때 dependency issue가 있을 register(R3)에 대해서는 R3b,R3c와 같이 이름을 주는 것   
register renaming은 true dependency issue는 해결하지 못한다. 이거는 순서를 못 바꾼다.   
true dependency issue가 발생할 register를 제외하고는 순서를 바꾸어도 결과에 문제도 없으면서, 성능도 높인다.   
   
data dependency issue(data harard)는 해결되었다.   
이제 남은 control hazard와 structural hazard는?   
--> cpu의 multi threading 기술이 위의 2개의 hazard에 대해 간접적(직접적은 아님)으로 도움을 준다. 전체적으로 시스템 성능을 높여준다.   
   
intel의 hyperthreading 기술이 명령어를 2개씩 가져오는 수퍼스케일라 동작을 해준다.   
   
---------------------------------------------------   
   
### MultiThreading   
   
thread : 명령어의 흐름/문맥(상태를 가진), 하나의 독립된 프로그램   
Thread context switching for multitasking:함수콜과 비슷한 느낌   
   
어떻게 한개의 cpu에서 다중의 쓰레드를 돌릴것인가?   
   
결과적으로 멀티쓰레드로 hazard들을 모두 해결하고, 성능 증가의 핵심이 된다.   
   
최근 AMD가 인텔보다 가성비가 좋은 cpu를 만들게 된 이유가 AMD의 멀티쓰레드 기술의 발전 때문이다.   
   
왜 멀티쓰레딩을 잘하는게 좋은가?   
1. To tolerate latency : A 쓰레드가 메모리 엑세스하느랴고 200cycle이 걸려서 cpu는 그동안 놀아야 하는데, 이를 피하기 위해 B쓰레드를 실행한다.   
cpu가 노는 시간을 줄일 수 있다.   
thread warping(in GPU. not in CPU) : 한 thread가 어디서 정체되면 휴지기처럼 보내버리고, 다른 thread를 실행한다.   
사용자입장에서는 2개의 쓰레드가 동시에 돌아가는 듯한 느낌. 시간차를 이용해서 성능을 높이는.   
이러한 아키텍쳐를 single instruction multithreading (sint)라는 기술이라 부름.    
멀티쓰레딩을 잘하려면, 중간에 노는 시간을 다른 쓰레드로 채우는 것을 잘 해야 함.   
2. to improve system throughput   
cpu자체를 멀티쓰레드 친화적으로 만들면, context switching 하는 시간을 줄일 수 있어서 시스템의 성능이 좋아진다.   
3. To reduce context switch penalty   
   
단점   
1. 하드웨어 비용 증가   
2. 결과적으로 싱글 쓰레드의 성능은 낮출 수 있다.    
A를 하다가 오래걸려서 그 사이에 B를 하는데 A가 끝났으나, B를 마무리해하고 A로 넘어가야 하므로 A가 끝났다는 응답을 늦게 받을 수 있다.   
A입장에서는 성능이 조금 느려진 것이다. 응답속도가 느려졌을니까.   
   
[멀티쓰레딩 종류]   
   
1. Fine-grained    
여러 쓰레드가 있는데, 매클락마다 쓰레드를 바꾸는 것임. 매클락마다 다른 쓰레드에서 명령어를 가져온다.   
   
멀티쓰레드 친화적인 하드웨어   
thread selector : 2-bit counter. mux에서 4개의 pc 중 하나를 선택한다.   
매클락마다 thread selector가 1씩 증가. 0123.   
   
단점 : 쓰레드 한개 단위(thread-wise)에서는 성능이 저조하다.   
장점 :   
한 쓰레드가 논다고 해서 다른 쓰레드가 노는 것은 아니다.(hw utilization 증가)   
-> system-wise 성능은 증가   
   
MIPS인데, 5개의 thread가 있다고 가정.   
그러면 data/control hazard를 해결한다. -> bubble도 사라짐   
data hazard : 파이프라인 안에 데이터를 요구하는 쓰레드가 1개만 존재하기 때문. 파이프라인 안에 데이터를 요구하는 명령어가 2개 있어야 종속이 생기는데   
control hazard : 점프도 파이프라인 stage 5개 안에 한쓰레드 1개만 들어왔기 때문에, 점프를 어디로 할지 알고 난 다음에 그 다음 명령어를 수행할 것이기 때문에, brach prediction할 필요도 없다.   
sturcture hazard 문제는 남아있다. 다른 쓰레드끼리 한 하드웨어를 공유하기 때문.   
   
   
- 단점   
1. hw 증가 : 다중의 pc, 다중의 register file, counter   
     
2. single thread performance 감소   
정확히는 1/N로 내려가지는 않는다. 1/N보다는 덜 내려간다.   
그 이유   
1) 한 쓰레드가 200 cycle 논다고 해서, 1000 cycle이 노는게 아니기 때문이다.   
2) dependency checking과 branch prediction에서 발생하는 버블이 사라졌기 때문에, 이로 인한 성능 향상.    
그러나 전반적으로 1/N처럼 내려가는 것으로 보인다.   
     
3. 자원 집중이 증가 : 노는 쓰레드가 없어지고, 많이 사용하게 되었다.   
소수의 하드웨어를 다중의 쓰레드들이 사용하려고 하는 확률이 높아진다.    
즉, structure hazard의 확률은 증가할 수 있다.   
   
4. 쓰레드간의 dependency를 체크해야 함   
   
5. (수퍼 스케일라의 경우) 쓰레드 내의 여러 명령어들간의 디펜더시 체킹, 브랜치 예측이 여천히 필요하다.   
   
(page10) 128개의 쓰레드, 1개의 쓰레드가 메모리 엑세스로 150 cycle 동안 지연되어도 1번 노는 정도밖에 안된다.   
   
   
2. Coares-grained   
fine은 자잘한것, coares는 큼직한것   
어떤 쓰레드에서 큰 지연이 발생하면, 그때만 쓰레드를 바꾸고, 자잘자잘한 때는 쓰레드를 바꾸지 않는다.   
   
- coarse와 비교해서 fine의 장점   
1)fine은 coares에 비해 구현이 쉽다.   
(매클락마다 바꾸는 것으로 정규화되어 있고, dependency checking과 branch prediction안해도 되니까.   
 물론, 수퍼스케일라에서는 다중 명령어 간의 dependency checking과 branch prediction을 하긴 해야함 ))   
그러나, coares는 큰 이벤트 발생 전까지 한 쓰레드 안에서 연산하니까 한 쓰레드 안에서의 dependency checking과 branch prediction 2가지를 해야한다.   
2)fine은 스위칭으로 인한 성능 오버헤드가 없다.   
fine은 스위칭이 자주 일어나기 때문에 다중의 pc값과 레지스터 파일을 가지고 있다.   
coarse는 스위칭이 자주 발생하지 않고, 큰 이벤트 발생시 쓰레드 컨텍스 스위칭한다.   
즉, 기존의 pc값과 레지스터를 스택에 올리고, 새로운 pc값과 레지스터 파일을 올려서 동작시키기 때문에. 스위칭으로 인한 오버헤드가 있다.   
   
멀티쓰레드 친화적인 하드웨어 -> pc값 여러개, 레지스터도 여러개 가지고 있는 환경.   
   
- coarse와 비교해서 fine의 단점   
fine은 단일 스레드 성능이 낮다.   
이 중에서도 중요한 것은 우선순위가 높은 쓰레드의 성능에 타격이 있다. 중요한 쓰레드가 늦게 처리된다는 문제 발생!   
coares는 우선순위를 높은 쓰레드를 먼저 실행하다가, 이 쓰레드가 지연되면 다른 쓰레드를 처리한다.   
사용자 입장에서는 coarse가 낫다. 우선순위가 높은 쓰레드가 먼저 처리되니까 (체감 성능상)   
coarse가 IPC(클락당 처리하는 명령어수)는 fine보다 낮을 수는 있지만, 체감 성능상으로는 더 좋을 수 있다.   

## 7. 학습 내용에 대한 개인적인 총평
+ 기말고사 범위의 내용을 강의를 다시 들으며 학습하였다.
+ 강의 내용이 워낙 어려운데, 비대면 수업이라 강의를 여러번 다시 볼 수 있어 학습하기 좋았다.
+ 지난 시험 범위까지 커버해야 해서 빠듯하게 시험 준비해야 한다.
+ cpu 성능향상을 위한 흐름을 파악하게 되었다.
+ 주말에는 multithreading의 SMT에 대한 내용과 메모리, 가상메모리에 대한 내용을 학습하고, 전범위 복습할 예정이다.

## 8. 다음 학습 계획
+ 컴퓨터구조 기말고사 대비