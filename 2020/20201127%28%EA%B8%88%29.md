## 1. 학습 날짜
+ 2020-11-27(금)

## 2. 학습시간
+ 13:00 ~ 18:00 (자가)
+ 19:00 ~ 24:00 (자가)   
+ 총 학습시간 : 10시간

## 3. 학습 범위 및 주제
+ 컴퓨터구조
+ 소프트웨어공학

## 4. 동료 학습 방법

## 5. 학습 목표
+ 컴퓨터구조 cache , virtual memory 학습
+ 소프트웨어공학 품질관리와 프로세스 개선 학습


## 6. 상세 학습 내용
+ 실제 코딩에 소요한 시간 : 0시간    
+ 컴퓨터구조 강의 수강 : 4시간        
+ 소프트웨어공학 강의 수강 : 3시간    
    
#### cache

- 9.11.3 Extremes of set associativity   

실제로는 다 쓰인다.   
cache layer 별로 어떤 것을 쓰는 것이 좋은 것인지 SPEC1006로 알아낸다.   
error free의 시스템을 만드는 것은 불가능하다.   

- 9.12 Instruction and Data caches   
캐시를 분리하는 것이 나을까?    
데이터, instruction은 분리하는 게 낫다.    
분리하는 구조인 하바드 아키텍처를 사용하는 것이 낫다.   

- 9.13 Reducing miss penalty   
miss rate을 줄이는게 중요. 이를 위해서는 캐시의 placement 중요, cache line의 크기, 그래서 spatial locality를 support하는 것이 중요.  cache size를 늘리면 좋긴 하나, cache 동작 속도가 느려져 그 레벨에 캐시를 엑세스하는 시간이 늘어난다. 원하는 것 많으나 현실적인 문제.   
miss penaly 줄이는 방법   
L2, L3의 존재 이유가 miss penalty를 줄이는 방법   
cache가 단계적으로 존재해서 penalty를 줄일 수 있다.   
상용적으로 보았을 때, 현재로써 반도체 공정이 cost effective하고, 성능 최적화한 방법아 L3까지이다. 앞으로 반도체 공장의 발전으로 DRAM 과 processor의 gap이 좁혀져 L4가 생길 것이다.   

cpu/memory performance gap   
cpu 의 성능은 매년 15~20%씩 증가하는데, memory는 10년에 33% 증가한다. 캐시가 없던 시절이 있었다. gap이 커지면서 캐시가 들어옴. 점점 상대적으로 메인 메모리의 속도가 느려지니까 캐시로 보완하게 되었다.   

- 9.15 Recapping Types of Misses   
Compulsory : 프로그램을 처음 엑세스 할 떄(부팅할떄) 발생하는 강제적인 miss   
Capacity: 캐시의 사이즈가 제한되어있기 때문에, 오랜전에 있던 데이터를 찾지 못하였다.   
Conflict: 캐시는 full아닌데, line이 full. 한 자리에서만 주고받고를 계속하여서 발생   
Fully associative는 conflict는 안 난다. 왜냐면, 비어있는 곳에 넣으면 되니까   
cache가 miss되어 사람이 느끼는 impact : Compulsory>Capacity>Conflict(부팅시>사람이 잘 느끼지 못함> 자주 발생하지 않는다)   
Compulsory를 해결하는 방법 : HDD -> SSD.   
Capacity는 잘 못느끼는 정도임. 물론 용량이 큰 프로그램을 돌릴 때는 자주 발생할 수 있다.    

- 9.16 Integrating TLB and Caches   
가상메모리의 전조   
cpu 다 0번지부터 시작된다. 그런데 컴퓨터의 물리적으로 0번지는 하난데 동시에 동작하는 SW는 많다.  빡침이 날 것임   
어떻게 동작하냐?   
가상의 세계에서 여러개의 SW는 분리되어 0번지부터 시작한다. 물리적인 0번지는 다르다.   
실시간으로 이것을 번역해줄수만 있으면 된다. TLB가 해준다.   
이 기능이 없으면 어떻게 되느냐?   
SW가 0번지가 아닌 각각 다른 특정 번지에서 시작해야 한다.   
또한 특정 SW를 사용하기 위해서는 모든 PC마다 사용하려는 번지를 남겨두어야 한다.   

- 9.19 Recap of Cache Design Considerations   
Direct mapped caches : 캐시가 temporal locality를 100% support 못해준다.   
Cache read/write algorithms : placement에 따라 알고리즘이 달라진다.   
Spatial locality and blocksize    
Fully- and set-associative caches : temporal locality를 support   
Considerations for I- and D-caches: structure hazard 때문에 분리해야 함   
TLB and caches :  가상주소에서 물리주소로 바꾸는 번역가. 엿보기하는 버퍼.     
Virtually indexed physically tagged caches : 학부수준으로는 힘들다.   

- 9.22 Performance implications of memory hierarchy   
cpu register는 latency가 거의 없다시피 한다.   
L1 : instruction queue가 없는 cpu는 3클락씩 안걸리고, 바로 register를 준다. 아키텍쳐마다 다르다.   

Simulated interleaving using DRAM : 여러개의 DRAM을 쓰게 될 경우, 스피드를 올리기 위해 DRAM을 번갈아쓰는 것    

9.24 Memory hierarchy of modern processors – An example   
temporal을 아래 단계로 갈수록 강조함? 왜?   
fully associative 는 하드웨어가 잔뜩 들어간다. 그렇게 되면, 느려짐.   
L3은 어짜피 50 클락 필요한데, 53클락 필요하다고 하면 큰 차이가 있겠냐. 한 두 클락 더 써서 hit rate을 늘리겠다.   

L1, L2 는 분리를 하여 core마다 가지고 있다. L3는 어짜피 느리니까 공유한다.   
여기서도 연구를 통해 최적을 조사한다.    

------------------------------------------------   

#### Virtual Memory

가장 이해하기 까다로운 부분   

- Motivation   
Virtual memory enables efficient and safe sharing of memory among multiple programs. : 이전 시간에 이야기 한 내용   
가상의 0번지를 가지고 있도록 함 -> 여러 프로그램이 물리적 0번지를 덮으려고 하는 것을 protect한다고 함   
각 프로그램은 자신의 프로그램의 부분만 assigne 해야 함. 다른 프로그램을 건들지 않아야 함.   
mapping은 hw와 os가 해준다, SW, 컴파일러는 알 바가 아니다.    
VM으로 동적으로 물리적인 주소에 프로그램 주소를 붙여준다.   
프로그램 입장에서는 0번지부터 시작하지만, 물리적인 주소는 같은 프로그램이더라도 pc마다 다르다.   

VM은 hdd의 남은 공간을 ram으로 쓰는 기능도 있다. 물론 속도는 느리다.   
8gb 넘어가면 그 소프트웨어는 결국 하드디스크로 내려야 함. 그래서 램 8->16의 성능차이가 크지 않다.   

- Page in VM   
- Page and Page Fault   
부팅하는데 Disk를 메인메모리를 올리느랴고 시간이 오래 걸린다.   
동작 중에는 필요한 부분만 메인메모리에 올려져 있다.   

page offset : page내에서도 몇번재 byte인지를 알려줌   

page fault는 굉장히 느리기 때문에 fault 비율을 줄여야 한다.   
그러므로 page가 충분히 커야 한다. 엑세스 타임이 많이 걸리기 때문에.   
너무 page의 크기가 커버리면, 엔트리의 개수가 작아지니까 temporal locality 손해본다.    
fully associative placement :느리니까 당연히 쓴다. 조금이라도 hit rate을 늘려야 한다.   
• Page faults can be handled in SW : SW는 느리지만, flexible하다. 어짜피 hdd 핸들할려면 시간 오래걸리니까 느린 SW 사용해도 차이가 느껴지지 않는다.   
VM uses write‐back: 너무너무 느리니까 wirte back을 한다.   

- Page Table(Placing a Page and Finding it Again)   

(page table + PC + registers) 만 알고 있으면, 재부팅해도 다시 이어서 작업할 수 있다.   
Each process has its own page table (+register) : 각자의 프로그램은 각자의 page table을 가지고 있다. 물리적 주소를 다르게 갖고 있기 때문에. page table register(시작점/포인터)도 다르게 갖고 있다.   
OS가 가상메모리를 할당해주고, page table을 업데이트한다   

- Size of Page Table   
프로그램이 많으면 , GB로 올라갈 수 있다.   

- TLB   
SMT와 TLB는 같은 레벨의 중요성을 가지고 있다.-->?   
데이터 엑세스 하려면 두번 엑세스 해야한다. 1.page table. 2.physical memory    
page table도 근처의 page을 읽을 가능성이 높다   
sepcial cache, 캐시처럼 최근 읽은 기록들을 가지고 있다. => TLB   

TLB의 매핑이 바뀔 수 있다. 그렇 경어 dirty bit 을 내려야 한다.   
Hit time 굉장히 빨라야 한다.   
Miss penalty : DRAM access   

- Steps in Handling a Page Fault   
trap : 멈추라는 인터럽트. os가 개입해서 hdd가서 page를 읽어 아무도 안쓰는 메모리 영역(free frame)에 넣고, page table 을 업데이트 함   
 6. cpu에 가져다 주면서 TLB도 업데이트한다.   

firmware는 시스템 소프트웨어인데 물리적 주소밖에 없다. 물리적 주소를 그대로 사용한다. 가상메모리를 사용하지 않아 VM을 사용하지 않는다. os가 필요하지 않다.    
ROM BIOS가 os시작전에 실행된다.  ROM BIOS가 펌웨어   


## 7. 학습 내용에 대한 개인적인 총평
+ virtual memory 에 관련된 내용은 자세하게 다루어지지 않아서, 작년 운영체제 강의에서 배웠던 내용들을 복습해야겠다.
+ 전체적인 진도를 다 나가서 복습을 통해 종합적으로 내용정리가 필요하다.
+ hdd/ssd 와 관련된 이론들은 어렵고, 구현이 복잡하고 까다롭다고 한다.
+ 소프트웨어공학 품질 관리와 프로세스 개선에 관련된 강의도 수강하였다.
+ 이에 대한 내용은 분량이 많아 report 작성을 생략하였다.

## 8. 다음 학습 계획
+ DB 프로젝트