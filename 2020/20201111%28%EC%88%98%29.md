## 1. 학습 날짜
+ 2020-11-11(수)

## 2. 학습시간
+ 14:00 ~ 19:00 (자가)   
+ 21:00 ~ 24:00 (자가)
+ 총 학습시간 : 8 시간

## 3. 학습 범위 및 주제
+ 컴퓨터구조 memory hierarchy, cache

## 4. 동료 학습 방법

## 5. 학습 목표
+ memory hierarchy, cache 학습


## 6. 상세 학습 내용
+ 실제 코딩에 소요한 시간 : 0시간    
+ 컴퓨터구조 강의 수강 : 3 시간    

#### Memory Hierarchy

* CSE는 0과 1의 세계(논리적 해석)
* EE는 몇 V,A인지를 판단(물리적 해석)

* > Idealism (이상향) : 현실은 그렇지 못하다.

* Pipeline(CPU입장에서 원하는 사항)
* - No pipeline stalls : address 주는 순간 데이터를 바로 뽑아주기를 원한다. stall이 없으려면 속도가 굉장히 빨라야 하는데 그렇지 못한다.
* - Perfect data flow (reg/memory dependencies) : 디펜던시가 없었으면 좋겠다.
* - Zero-cycle interconnect (operand communication) : wire(선)들도 딜레이가 없었으면 좋겠다.
* - Enough functional units : 하바드구조. 분리해서 좋은점은 structure hazard 없다. 가격이 저렴해서 여러개 샀으면 좋겠다.
* - Zero latency compute : 지연도 없었으면 좋겠다.
* 
* Instruction Supply(Memory 입장)
* - Zero-cycle latency(time)
* - Infinite capacity
* - Zero cost : 저렴한 가격
* - Perfect control flow
* 
* Data Supply
* - Zero-cycle latency
* - Infinite capacity
* - Infinite bandwidth : 명령어 하나가 무지하게 큰 데이터를 요구할 수 있는데, 그 떄 한 클락만에 전달하고 싶다.
* - Zero cost
* 
* > The Memory Hierarchy(메모리 하이라키(계층)
* 성능의 진짜 핵심은 메모리를 어떻게 다루느냐. 굉장히 중요! 왜냐면 메모리가 굉장히 느리기 떄문.
* 
* L1 cache는 core 안에 있다. data와 instruction이 2개의 캐시로 분리되어 있다.
* L2 cache는 각 core 옆에 하나씩 붙어있다. data와 instruction이 하나로 뭉쳐있다.
* L3 cache는 4개의 코어가 공유한다. 크다.
* DRAM은 L3크기만한 chip 여러개로 묶여있다. 물리적인 크기 차이가 크다.
* 
* Higher bandwidth is more expensive
* - Need more banks(메모리를 구성하는 묶음), more ports(핀이 많아서 한번에 많이 보내주든지), higher frequency(단위시간당 많이 보내준다), or faster technology(미세공정)

* 이상과 현실은 다르다
* 
* > DRAM
* - memory cell
* 으 모양 : trasistor중 gate
* gate가 0(논리적 0)이 되면 연결(MOS(metal oxide Semiconductor)에서)
* gate가 1(논리적 1)이 되면 끊김
* 스위치 역할. 반대는 NMOS
* 
* 캐패시터 : 전자를 저장. 쌓는다.
* write : gate 0이라 연결되고, 1을 쓰면 전자가 캐패시터에 쌓인다. 0을 쓰면 캐패시터의 전자가 나온다.
* read : gate 0이 되면 연결되어, 캐패시터에 쌓인 전자가 밖으로 흘러나오면서 1인지 0인지를 읽어낸다.
* (sense amplifier : 전자가 조금 흘러나오면 증폭시켜 데이터를 무엇인지 빨리 알아내는 회로)
*  
* - DRAM은 왜 dynamic인가? 
* 캐패시터의 전압이 시간이 흐르면서 감소한다. data가 날라가게 된다.(누설전류가 생겨 전압을 잃는다. CS입장에서는 시간이 흐르면 데이터가 뒤집힌다,)
* data를 날라가지 않도록 주기적으로 refresh를 해준다. DRAM는 보통 10ms마다 해준다.
* 10초정도 refresh를 하지 않으면 데이터가 날라간다.
* 데이터가 시간 지나면 동적으로 날라간다.
* 
* 트랜지스터와 캐패시터의 크기가 비슷. 트랜지스터 위에 캐패시터를 쌓아서 물리적인 위치상 하나의 자리만큼만 차지한다.
* -> 가격이 저렴
* SRAM은 static : refresh를 안해도 데이터가 안 날라간다. 그러나 트랜지스터를 많이 사용해서 공간을 많이 차지하여 비싸다.
* 
* > SRAM
* write : gate가 0이면 연결되어 10배 이상의 강한 전류가 흘러(인버터에 흐르는 전류에 비해) 데이터를 쓴다. gate 1이면 연결이 끊겨, 인버터 두개 사이의 전류가 흘러 데이터를 가지고 있다.  
* 즉, data refresh를 안해도 데이터가 날라가지 않는다.
* read : gate 0이 되어 연결되면, 인버터로부터 전류가 흐르고, 증폭시켜 읽는다.
* invertor에 트랜지스터 2개가 들어간다. 총 트랜지터 6개 들어간다. 면적으로 따지면 DRAM보다 6배 차이가 난다.
* 
* > Memory Bank Organization and Operation
* row 선택하고 col 선택한다.
* row를 여러 개로 많이 나누고, col의 개수를 적게 하여 전력 소모를 줄일 수 있다.
* -> Bank구조
* bank enable : 어떤 bank를 가려고 하는지
* bank도 커지면 속도가 느려진다.
* 효과적인 bank size/개수를 결정하여 제품을 생산한다.
* 
* Amplify : 시간을 줄이기 위해 증폭시킨다. 조그만한 신호가 나오면 증폭시킨다.
* 
* SRAM도 마찬가지로 bank 구조 사용한다.
* 
* > DRAM vs. SRAM
* DRAM : 수동소자, main memory에 사용된다.
*  Slower access (capacitor) : MUX 단위가 다르다. MUX의 depth가 달라진다(하드웨어 size가 증가), 즉, 데이터 뽑는 속도가 느려진다. 한꺼번에 많은 데이터를 뽑을 수 있다.
*  Higher density (1T 1C cell) : 집적률이 높다.(6배 정도까지)
*  Lower cost : 싸다. 왜냐면 공간을 적게 차지하기 때문. 1bit를 저장하기 위해 필요한 단위면적이 작다.
*  Requires refresh (power, performance, circuitry)
*  Manufacturing requires putting capacitor and logic together
* SRAM :인버터는 능동소자. cache에 사용된다. 캐시는 DRAM에 비해 굉장히 빠르다.
*  Faster access (no capacitor)
*  Lower density (6T cell)
*  Higher cost
*  No need for refresh
*  Manufacturing compatible with logic process (no capacitor)
* 
* > The Problem
* - Bigger is slower
* sub-nanosec : Shorter in duration than a nanosecond. 0.25nanosec
* L1 cache 와 Cpu는 sub-nanosec이라서 연동이 가능하다. 대신 L1캐시의 사이즈가 512byte로 작다
* 
* L1과 DRAM의 차이
* 4gHz는 1클락이 0.25nanosec -> 50nanosec의 1/200. 즉 데이터 읽을 때 200cycle정도의 차이가 발생한다. 그래서 메모리 읽을때 200cycle정도 차이가 난다고 한것이다.
* (요즘은 더 캐시의 속도와 메모리 속도가 빨라지긴 했지만 비율은 비슷하다.) 
* 
* 5GHz까지는 소자와 기술의 발전으로 가능했지만, 그 이상은 발열때매 힘들다. (상용 pc에서)
* 온도를 영하로 낮추고 클락수를 높여 성능을 높이는 연구 -> 과학적인 연구 목적으로.. 
* 
* 부팅 속도가 느린 이유 : 하드디스크로부터 메모리로 올리는 속도가 느리기 때문이다.
* 
* 요즘은 hard disk < 0.1달러 per Gb
* 무어의 법칙 : 하드웨어는 2년마다 2배씩 증가한다. 가격이 반으로 내려간다.
* 이런 가격들은 시간이 지남에 따라 scale 된다. 무어의 법칙 때문
* 무어의 법칙이 왜 가능한가? : 반도체 공정의 발전으로 가능함. 30%감소된(면적은 제곱이라 0.5감소) 새로운 공정이 나오는데 2년이 안 걸린다.
* 10나노 공정 : 10*10=100
* 7나노 공정(30%감소) : 7*7=49
* -> 50%감소 
* 
 -----------------------------------------------
* > Why Memory Hierarchy?

* 여기서부터 본론.
* 프로세서가 필요로 하는 데이터를 빠른 레벨에 유지시키는 것이 중요
* -> 목표하는 fast + large를 이룰 수 있다.
* 
* > Locality  : 지역 한정성
* - Temporal Locality : 시간적인 데이터의 지역한정성. 높은 확률로 한 일을 다시 할 것이다. 변수 초기화 이후 변수를 사용할 확률이 크다.
* - Spatial Locality : 변수 a를 요구하면, b,c,d도 같이 준다. a 쓰는 순간 b,c,d를 쓸 확률이 높을 것이다. 
* --> 컴퓨터가 동작하는 것을 관측하면서 발견하였다.
* 
* DRAM은 덤프, cache는 스포츠카
* DRAM는 느리지만 한번에 많은 데이터를 줄 수 있다.
* 
* cache block : 한 블락이 자기가 받은 것을 다 쌓아놓는 것 . 32bit 시스템에서 4바이트가 명령어 한개
* 64byte block은 8byte를 한 라인에 다 쌓는 것이다.  --->? 설명이 조금 이상
* 
* > Caching in a Pipelined Design
* L1 cache가 하드웨어 커지면 속도가 느려지는데, 어느순간부터 cpu 보다 느려지면 연동이 불가능하다. 
* 물론 L1이 크면 클수록 좋지만(더 많은 데이터를 넣을 수 있어 DRAM까지 갈 필요가 없기 때문), 불가능하다. cpu와 같은 속도가 필요하다.
* 
* L2 : L1보다는 4배 정도 느리다, 관찰 및 분석하여 최적의 size를 결정하였다. 
* 
* 캐시에 새로운 데이터를 넣으려면, 가장 오래전에 사용한 데이터를 지워야 한다.
* L1에서 데이터를 못찾으면 L2에서 찾는다. DRAM에서 찾는 것보다는 패널티가 적다.
* 
* >A Note on Manual vs. Automatic Management 
* cache management
* - Manual : 소프트웨어로 데이터를 어디에 놓을지 결정
* (CUDA programming : data를 어디에 올려놓는가를 결정. 짜는 사람에 따라 성능이 제각각이다. GPU에서 프로그래밍하는 것. 알고리즘 잘하면 추천. 캐시와는 다른 의미. 전문가적 지식이 필요하다. 소트웨어 엔지니어의 하드웨어 감각이 얼마나 좋은지에 따라 성능이 달라진다.)
* - Automatic : 하드웨어가 알어서 결정. 캐시는 하드웨어. 하드웨어가 하면 순식간에 가능한데 이것을 소프트웨어가 한다고 하면 속도가 느려진다. 자동화해서 돌려주는 것.
* 32KB = 8000개의 명령어 (4byte에 명령어 1개)
* 캐시에 데이터가 존재하면 hit, 없으면 miss
* 메모리 계층이 없다면, cpu의 4GHZ가 무의미하다.

## 7. 학습 내용에 대한 개인적인 총평
+ 강의 내용이 다소 어려워 한 시간 강의를 두 시간동안 필기하며 들었다.
+ cpu를 마치고, 이제 메모리 위주로 학습하고 있다.
+ 무어의 법칙을 비용적인 측면에서 이해하고자 ram과 hdd의 가격을 비교하기도 하였다.
+ 전 범위 시험을 감당하기에는 너무 부담이 크기 때문에, 한 번 복습하는 시간이 필요하다..
+ 저녁에는 libft 또는 DB 프로젝트 개념적 설계를 진행할 예정이다.


## 8. 다음 학습 계획
+ DB 물리적 설계
+ LIBFT part 2 