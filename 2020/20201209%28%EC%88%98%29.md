## 1. 학습 날짜
+ 2020-12-09(수)

## 2. 학습시간
+ 13:00 ~ 19:00 (자가)   
+ 20:00 ~ 24:00 (자가)
+ 총 학습시간 : 10시간

## 3. 학습 범위 및 주제
+ 컴퓨터 구조 pipeline hazard, branch prediction

## 4. 동료 학습 방법
+ 대학 동기와의 토론

## 5. 학습 목표
+ pipeline hazard, branch prediction 학습


## 6. 상세 학습 내용
+ 실제 코딩에 소요한 시간 : 0시간    
+ 컴퓨터구조 강의 수강 : 3시간    

### pipeline hazard
<Pipeline Hazards>   
   
파이프라인 장점 : 성능이 배가 된다.   
   
구조적 위험 : 하드웨어 구조적으로 파이프라인이 안되는 문제 발생   
데이터 위험 : 데이터의 흐름에 디펜던시가 생겨 꼬인다.   
컨트롤 위험 : 브랜치 명령어 실행시 파이프라인 기반의 연산이 어려워짐   
   
공통적인 솔루션 : 파이프라인을 안하면 된다. but 성능이 안 올라간다.   
   
[1. Structural Hazard]   
만약 메모리가 하나라면, load의 DMem(load 명령어는 메모리를 엑세스한다)과 instr3의 Ifetch에서 메모리를 동시에 사용한다.   
데이터 메모리와 명령어 메모리를 분리하면 된다. 분리하면 다른 하드웨어니까 문제가 일어나지 않는다   
분리하지 않는다면?, stall 하면 된다.   
   
instr1의 Dmeme은 메모리 엑세스를 안한다고 가정.   
   
파이프라인이 정지되었다 = pipeline stall = pipeline bubble   
   
page4 : 파이프라인 스테이지 단위의 시간흐름   
page5 : 명령어단위의 시간흐름   
   
(page6)   
Dealing with structural hazards   
   
1.stall   
   
2.pipeline hw resource   
multi-cycle resource: 겹치는 사이클의 메모리에 대해서만 클락을 2배로 늘리고, 첫번째 클락은 Dmem를 위해 쓰고, 두번째 클락은 ifetch를 위해 쓴다.    
-> 적용가능하기 어려운 경우가 더 많다. 운 좋을 때는 된다.   
   
3. Replicate resource   
Harvard Architecture   
가격이 싸면서 분리가능한 자원   
보통 퍼포먼스 올리는 것이, 하드웨어 복제하는 것보다 의미가 있다 싶으면 Replicate resource를 하고, 의미가 없다 싶으면 stall을 한다.   
   
>.floating point 는 ALU 연산이 연속적으로 여러 클럭동안 사용한다, 그래서 뒤 명령어가 밀린다.     
   
   
[2. Data Hazard]   
RAW(“Dependence”)는 MIPS에서 일어난다.   
WAR(“anti-dependence”), WAW(output dependence)은 MIPS에서 일어나지 않지만, 나중에 더 복잡한 파이프라인에서 발생한다.   
   
> Bypass/forward/shortcircuit   
RAW를 해결하기 위해서는 3클락을 stall 하면 된다.   
stall을 안하고, 데이터가 필요한 곳으로 데이터를 전송해주는 기술, 원래 있는 데이터 패스 말고 새로운 데이터패스를 추가시킨다. 그래서 하드웨어가 복잡해진다.   
데이터가 있는 시점에서 ALU에 가져다 준다.   
   
stall을 다 없앨 수는 없다. reduce(o) avoid(x)    
(page16) load인 경우 stall을 MIPS안에서는 피할 수 없다. 1클락 stall해야 한다.   
파이프라인 구조에 따라 다르다.   
  
- Pipeline Scheduling   
Instruction scheduled by compiler - move instruction in order to reduce stall   
SW는 순서가 반대.   
lw 뒤에 바로 add오면 1클락 stall해야 한다.   
즉 위의 문제는 총 10 clock이 필요하다.   
   
아래 문제는 8클락이 필요하다.   
순서에 따라 클락이 달라진다.   
   
컴파일러는 번역만 하는게 아니라 코드최적화(스케줄링(optimizing))도 한다   
% loads stalling pipeline : load시 stall이 발생하는 확률     
   
[3. Control Hazard]   
-> 가장 성능에 파격적인 영향을 미치면서도, 해결방법이 어렵다.   
   
jump : unconditional jump   
branch : conditional jump   
   
(page21) 문장 중요   
데스티네이션 알기 전에 새 명령어를 가져오지 않는다.   
   
8 : beq r1,r3,24   
8+4+24=36   
=> 4을 왜 더해주는가? .기본적으로 pc+4를 한다.   
--> 음, single cycle에서는 pc+4+(offset*4)로 설명되어있네?   
   
(page 23)   
성능이 반으로 떨어짐.    
성능 차이는 곧 가격   
   
CPI=1, 30% branch(명령어의 30%가 branch), Stall 3 cycles -> new CPI = 1.9!   
명령어 3개마다 1번 논다   
branch 만나면 명령어 3개씩 안가져온다.   
>> 4 cycle (branch 1 cycle + stall 3 cycle) * 0.3 + 1cycle * 0.7 = 1.9   
   
load는 나올 확률도 10%밖에 되지 않는다. load가 발생하면 1번의 stall이 발생할 수도 있다, 심지어 무조건 발생하는 것도 아니다.   
load 다음에 바로 쓰는 명령어가 있을 경우에만 stall하는 것이니까.(컴파일러의 스케줄링)   
load로 인해서는 고작 5% 정도의 성능차이가 발생한다.   
그러나 branch로 발생하는 성능차이는 크다   
   
Two part solution to this dramatic increase:   
– Determine branch taken or not sooner, AND : 브랜치 할것인지 아닌지 알아내고   
– Compute taken branch address earlier : 할것이라면, 어느 주소로 점프할 것인지 빠르게 계산해야 한다.   
   
   
[ 5 branch hazard alternatives ]   
1. 그냥 stall   
실제로 명령어중 branch의 비율이 생각보다 많다.(25%)   
3 stall이면 사실 파이프라인 하는 의미가 없다.   
심지어 load도 버블을 만드니까   
   
2. Branch가 not taken 한다고 믿어, 원래 하던데로 pc+4하자.   
-> pc+4가 아닌데(branch해야하는데) pc+4 해서 pc+4에서 다음 명령어 가져와서 진행하다가 branch해야 했었다는 것을 알아버림,   
그 순간 진행하던 다음 명령어들을 NOP(no operation)처리한다.(효과가 없도록) -> pipeline flush(비운다)   
->실제로 47%가 not taken한다.(2번 중 한번꼴로 맞추는 효과.)   
   
3. taken한다고 믿는 거임   
MIPS still incurs 1 cycle branch penalty -> ID 단계가 필요. target address를 decode해야 하니까.   
Other machines: branch target known before outcome -> BTB   
설사 브런치 안하면, pipelin flush(비운다)한다.   
   
1이 제일 무식, 2가 도박(43%)로, 3은 53%확률로 도박   
   
4. cpu 2개 만들어서 같이 동작하다가 맞는쪽을 끝까지 실행시키자.   
-> 너무 무식해. cpu 2개 만들어야 하니 돈이 2배 든다.   
   
5. Delayed Branch   
branch에 영향을 주지 않는 명령어들을 branch 뒤에 넣는다(위험한 3개 명령어 자리에)   
->컴파일러의 성능의 영향을 받는다. 컴파일러가 branch 뒤에 넣을 명령어들을 찾는다.   
브랜치 뒤에 올수 있는 영향을 주지 않는 명령어는 0개,1개,2개,3개가 올 수 있다. 3개가 오지 않는다면, 어쩔 수 없이 패널티가 있을 수 밖에 없다.   
   
+ Taken backwards Not taken forwards.   
branch를 봤더니 음수면(뒤로 거슬러올라간다) taken, 양수면(앞으로 간다) not taken 할거라고 policy를 정했다.   
misprediction rate가 굉장히 낮아짐. 어마어마한 혁신!   
branch는 if/while/for문에서 많이 사용하는데 while/for문에서 뒤로 갈 확률이 매우 높다.   
그래서 Taken backwards Not taken forwards이 방법이 의미가 있는 것이다.   
   
연구라는 것은 분석/관찰 후 법칙을 이해하고, 소스를 이해하고, 소스를 활용하는 것   
   
Static하다 : 결정한 것. 바뀌지 않는다. cpu가 돌기 전에 미리 해결하는 방법. Dynamic은 cpu가 실시간으로 벌어지는 일들을 해결하는 것.    
컴파일러는 static하게 Prediction of Taken/Untaken Branches 을 결정한 것이다.   
컴파일러는 delayed slot을 이용한 향상된 전략을 사용한다.   
– Backward branch predict taken, forward branch not taken   
– Profile-based prediction: record branch behavior, predict branch based on prior run   
   
(page 28)   
파이프라인 힘들게 하는 것 : 파이프 라인 버블을 만드는 모든 경우   
1.address mode : MIPS에는 없고, 인텔Cpu에는 있다. address를 갔는데, 또 다른 address를 가르킨다.   
indirect address mode. 데이터 메모리를 두 번 access해야 해서 메모리 엑세스 시간이 길어진다. 그 결과 pipeline bubble 생긴다.   
   
irregular event를 발생시키거나, 한 하드웨어를 오래 붙잡고 사용하면 파이프라인을 힘들게 한다   
   
2. Memory-Memory Move Instructions   
3. Condition Codes   
4. Multi-cycle instructions,   
5. A very lengthy instruction,   
6. Multi-Cycle Operations(floating point(FP)연산) 이 파이프라인을 힘들게 한다.   
ALU 연산마다 연산에 걸리는 시간이 다르다.   
   
>page31   
i+2을 뒤로 미뤄주어야 한다. WB를 i+1의 WB와 같은 위치 또는 뒤로 미루어야 한다   
WB이 다른 명령의 WB과 동시에 일어날 수도 있다. 이건 상황에 따라 다르다.   
   
>Summary   
harzard가 성능을 제약한다. 파이프라인 버블을 만들기 때문.   
복잡한 연산은 파이프라인을 어렵게 만든다.   
컴파일러가 문제를 해결할 가능성을 조금 가지고 있다. 그러나 그게 크지는 않다.   
   
+ 앞으로 결정적인 영향이 큰 방법들을 배우게 된다.   
-------------------------------------------------------------------------   
   
### Branch Prediction   
   
사실 명령어가 branch인지도 첫 클락에도 알 수 없다. 2번째 클락인 ID에 들어가야 무슨 명령어인지 알 수 있다.   
   
pipeline full하는 것이 어려운 문제다. 명령어 간의 실행순서를 정확히 맞추면서, 파이프라인을 채우는 것이 굉장히 어렵다.   
   
stall하는 기술은 회사 망한다.   
   
Branch Prediction : 브랜치 명령어가 점프할지 안 할지 예측하자.   
   
어떤 CPU는 한 클락에 명령어 여러개(W)가져올 수 있다. MIPS는 한클락당 명령어 하나 가져오지만,   
N : 브랜치로 인해 stall 해야 하는 클락 사이클 개수. branch 명령어 이후 확신할수없는 cycle/stage 개수.   
branch를 잘못 예측하면 N * W만큼 손해다.(MIPS CPU안에서는 1*3=3개씩 손해다)   
      
정확도가 95%여도 성능이 반으로 떨어진다.   
   
N: 파이프라인 stage 수. 위의 N이랑 다른 의미.   
W: Fecthing W instructions per cycle. 한번에 가지고 올 수 있는 명령어 개수.   
pipe stage가 20개인데, 한번에 가져올 수 있는 명령어의 개수가 5개이니 총 100개 명령어가 20개의 파이프라인 stage 안에 있을 수 있다고 생각하면 된다.   
   
assume1 : 명령어의 20%는 branch이다   
assume2 : 매 5번째 명령어가 branch이다.   
assume3 : 우리는 ALU에서 branch가 점프할지 말지 결정되었지만, 여기서는 20번째 stage에서 결정된다.   
   
100% : 1 clock cycle에 5개의 명령어 가져오니까 100 clock cycle에 500개의 명령어를 가져온다.    
   
99% accuracy : 100 개의 브랜치 중 1개의 브랜치를 못 맞추는 경우.   
99%의 정확도라는 것은 100개 중 99개 명령어는 brach prediction을 맞추고, 1개는 못 맞췄다.   
   
전체 500개의 명령어중 브랜치는 100개. 100개중 1개가 miss. (정확도가 99%이니까)   
못 맞춘 1개의 경우 앞의 20개의 stage들을 싹 지워야 한다.   
   
또다른 말로, 전체 500개의 명령어의 1%는 5개의 명령어.   
5개의 명령어 중 1개가 브랜치. 즉 1개의 브랜치가 miss된 것임.   
   
1개의 stage당 5개의 명령어를 가지고오니, 총 5*20=100개의 명령어(실제로는 95~99개의 명령어)를 지워내야 한다.   
이걸 다시 메꾸려면 20 cycle이 필요하다.(20cycle * 5개의 명령어 = 100개의 명령어)    
    
98 % : 140사이클   
   
95 % : 200사이클   
95%라고 할지라도 성능은 반으로 떨어진다.   
   
즉, 브랜치에서 점프할지 안할지를 맞추는 정확도가 50%라면 성능이 굉장히 낮아질 것이다   
   
[Branch Prediction]   
다음 fecth할 주소를 예측하자.   
예측하기 위해서는 다음 3가지가 필요하다.   
1. fetch한 명령어가 브랜치인지. 뽑는 순간 브랜치인지 알아야 함   
2. 브랜치의 방향. 브랜치가 점프할지 안할지.   
3. 점프할 것이라면, 브랜치 타겟 주소는?   
   
>BTB   
0이면 원래대로, 0이 아닌값이면 branch라고 생각 (요구사항 1 만족)   
0이 아닌값-> 이전에 jump한 주소가 저장되어있다.   
BTB는 jump한 기록이 남아있다.(요구사항 3 만족)   
처음 branch 만나면 틀리고, 그 이후로부터는 알 수 있다.   
   
명령어가 브랜치인것도 알았고, 타겟주소도 알았어. -> 이전의 기록을 보고.   
그럼 브랜치는 점프할 것인지 안 할 것인지를 알아야 함(요구사항 2) -> 이건 점쟁이.   
   
Compile time(static)   
지금까지 배웠던 것들.   
-> 무조건 간다 안간다 하는 것도 브랜치인지 알아야 하고, 무조건 간다 하더라도 어디로 갈지 알아야 한다. BTB가 있어야한다.    
-> 결국 컴파일 타임에 있는 방법들은 안쓰고, 런타임에 있는 방법들을 쓴다.   
   
Run time(dynamic)   
이제 배울 내용들.   
요즘은 ai 방법도 한다.   
   
>direction predictior(요구사항 2 : branch 할 건지, 안 할 건지)   
   
1. State Machine for Last-Time Prediction   
저번에 안 갔으면(not taken) 0 , 갔으면(taken) 1이 기록되어 있다.   
->Last time prediction(single-bit. 1bit.)  : 이 방법만 해도 컴파일 타임 방법보다 좋다. 80~90% 정도롤 맞출 수 있다.   
이 방법을 더 보완한 방법이 다음 방법.   
   
2. State Machine for 2-bit Counter(bimodal prediction) : Hysteresis Using a 2-bit Counter   
한번 뒤집혔다고해서, 넘어가지 말자. 경계지점(hysteresis)을 만들자.   
->2비트로 만들자(bimodal prediction). 85~90%의 정확도.   
그러나 아직 정확도가 부족하다. 정확도의 1%의 차이도 큰 성능차이가 있다.   
   
>>Two-Level Prediction   
   
1. Global branch correlation   
motivation : 근접한 제어문(if문)끼리의 연관성이 있을 수도 있다    
이전까지는 각각의 브랜치가 과거의 기록을 보고 맞추었다면,   
프로그램의 실행중에 있는데, 프로그램의 흐름에 따라 브랜치를 taken할지 not taken할수도 있다.   
    
GHR(global branch history register) : shift register. 최근 처리한 branch 결과 history를 저장해놓는다.   
taken은 1, not taken은 0. 16비트면, 최근 16번의 브랜치 처리 결과가 저장되어있다. 1개의 기록이 추가되면 마지막 16번째는 밀려서 없어진다.(shift left)   
   
그 다음 GHR이 가르키는 PHT를 쫓아가서 2bit-counter를 읽는다.   
PHT의 MSB가 0이면(00,01) 안가고, 1이면(10,11) 간다.(2-bit counter에서)   
PHT는 GHR의 패턴을 가졌을 때 점프를 했는지 안했는지를 저장해 놓았다.   
   
이 2단계를 거친다. 그래서 2 level Global history branch predictor.   
   
---> 이 논문 발표된지 5년 후에 4비트 GHR을 한 CPU인 Intel Pentium pro가 개발됨   
   
그후로 3년이 지나고, 개선된 논문이 발표되었다. biased branch filtering (page29. ~~~.MICRO 1994)   
   
   
그런데, 같은 PHT를 가르키는 branch들이 서로를 방해하게 되는 문제가 있다.   
서로 반대인 branch들이 같은 PHT를 가르키게 되면 확률이 굉장히 떨어진다.   
2 level global history branch predictior를 사용하다 보니, 이런 경우가 많았다.   
   
- 이런 방해를 줄이기 위한 방법   
1. PHT 비트 수 늘리자. 많은 양을 기억하자.   
-> PHT 엔트리 수가 급격히 증가. 1비트당 2배씩 증가. 하드웨어적으로 부담이 크다. 하드웨어적으로 2배만 되어도 부담이 크다. 특히 cpu는 더욱.   
   
2. highly-biased 브랜치를 걸러내자   
이 방법은 당연히 사용한다.   
필터링해서 걸러낸다고, 이 문제가 아예 없어지는 것은 아닌다. 여전히 방해하는 문제가 존재한다.   
static의 forward/backward 처럼 highly-biased branch는 무조건 점프다 아니다라는 것을 고정시킨다.   
   
결론적으로 다양한 방법을 섞어서 사용한다.(hybrid)   
branch prediction할 떄 branch에 대해서 한 가지 방법만을 사용하지 않는다.   
   
3.(답) Two-Level Gshare Branch Predictor : pc값과 GHR을 XOR한다.    
프로그래머, 프로그램마다 바어이스되는 경향이 있어서, GHR(global branch history register)의 좋은 장점(패턴에 따라 특성을 발견할수 있다는)을 잘 살려내지 못한다.   
특정 PHT로 바이어스되면 interference하는 문제가 생긴다. 같은 PHT을 가르키지 않도록 하자. 찢어지게 하자.   
각 명령어마다 pc값은 unique하다. 고유한 pc값과 GHR을 XOR해서 가르키는 PHT를 분리하자.   
물론 우연히 XOR 한 결과가 같은 것들이 있을 수 있지만, 그 확률이 매우 낮다.   
XOR 안 해서 GHR이 같은 것들에 의해 interference되는 문제보다 효과가 굉장히 좋다.   
   
branch address : pc값   
   
4. Gskew predictior    
Gshare는 XOR만 하는데 XOR만 하지 않고,  and, or 등의 다양한 function들을 추가한 것. 3개의 결과를 보고, majority vote를 찾음.   
일반적으로 맞출 확률은 Gshare에 비해 좋지만, 하드웨어 양이 증가한다. 좋아지는 효과에 비해 비용이 많이 들기 때문에 실제로 사용하지 않는다.   
모든 경우에 Gskew가 Gshare보다 좋은 것은 아니다. 소프트웨어의 특성마다 다름.   
   
   
정확도를 더 높이고 싶다.(왜? 1~2%의 정확도 차이가 크기 때문에)   
   
>>Two-Level Prediction   
1. Global branch correlation (위에서 공부한 내용)   
2. Local branch correlation   
특정 브랜치를 위한 히스토리를 저장한다.   
for(i=1; i<=4; i++); 에 대해서 3번의 반복은 같은 backward branch 하고 1번은 branch안한다는 것을 100% 알 수 있다.   
for문에서는 100% 맞출 수 있다. 그러나 단점이 있다.    
단점1 :for문에서는 잘 맞는데, if문은 패턴이 정적이지 않고, 동적이다. while문도 동적이다. iteration 횟수가 그때마다 다르다. for 문한테는 100%좋다.   
단점2: per branch. branch가 무지하게 많은데, branch마다 history register 만들면, 하드웨어가 무지하게 많이 필요하다.    
   
(page39)   
왼쪽 : global   
중간 : 변종. branch 묶음이 하나의 PHT를 공유. per set of branchs   
오른쪽 : local. PHT per branch    
   
   
- hybrid branch predictor   
Can we do even better?   
특정 성향을 발견했다. 브랜치마다 특징이 다르다는 관찰. 이질적이다.   
-> Hybrid Branch Predictor. 성향에 맞게 적용하겠다.   
-> selector(이 브랜치는 어떤 prdictor를 사용할지 선택해야 함) 필요하고, 여러 하드웨어도 필요하다.   
hybrid하면 90-97%의 평균적인 예측 정확도가 나온다.   
+ 이것보다 best? : ai branch predictor : 대학원 과정   
   
1bit -> 2bit -> global -> local -> ai    
cost가 낮은 것부터 사용해서 hit rate을 극대화한다.   
우측으로 갈수록 branch prediction의 정확도는 높아지지만, 하드웨어의 양은 늘어난다.   
   
요즘 모든 고차원적인 프로세스들은 hybrid(+ai 추가된)를 사용한다. 1bit가지고도 잘 예측하면 1bit쓰고, 안되면 그 다음단계로 사용하는 hybrid branch predictor를 사용하고 있다.   
   
단점   
selector 필요.   
longer access latency : 엑세스하는데, predictor가 여러개니까 하나쓸때보다 골라오는게 시간이 더 걸릴 수 있다는 것.   
   
그러나 장점은 better accurancy, 정확도는 곧 성능. 성능은 곧 돈.   
    

## 7. 학습 내용에 대한 개인적인 총평
+ branch는 cpu 성능의 큰 영향을 미친다.
+ branch로 인해 성능이 저하되는 것을 최소화하기 위한 단계적인 연구결과들을 학습하였다.
+ cpu의 성능은 branch prediction accuracy의 작은 차이에도 크게 달라진다.
+ branch prediction의 흐름을 따라 이해하였다.
+ 컴퓨터구조 중간고사 끝!

## 8. 다음 학습 계획
+ 소프트웨어공학 설계,구현 학습